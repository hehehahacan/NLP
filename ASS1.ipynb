{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpongeBob  = '''\n",
    "海绵宝宝= 海绵宝宝 派大星 蟹老板\n",
    "自己 = 我 | 本宝宝 |派大星我们\n",
    "寻找 = 看看 | 玩玩 |去捉\n",
    "活动=  捉水母 | 蟹黄包\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "Partick = '''\n",
    "Partick = 寒暄 询问 业务 结尾\n",
    "寒暄 = 称谓 打招呼 |打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 海绵宝宝 | 蟹老板 \n",
    "打招呼 = 你好吗 | 你好\n",
    "询问 = 你无聊吗想去 | 你想去\n",
    "业务相关 = 去 业务\n",
    "业务 = 吃东西 | 打水仗 |捉水母\n",
    "结尾 = 吗？\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grammar(grammar_str, split='=', line_split='\\n'):\n",
    "    grammar = {}\n",
    "    for line in grammar_str.split(line_split):\n",
    "        if not line.strip(): continue\n",
    "        exp, stmt = line.split(split)\n",
    "        grammar[exp.strip()] = [s.split() for s in stmt.split('|')]\n",
    "    return grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Partick': [['寒暄', '询问', '业务', '结尾']],\n",
       " '寒暄': [['称谓', '打招呼'], ['打招呼']],\n",
       " '称谓': [['人称', ',']],\n",
       " '人称': [['海绵宝宝'], ['蟹老板']],\n",
       " '打招呼': [['你好吗'], ['你好']],\n",
       " '询问': [['你无聊吗想去'], ['你想去']],\n",
       " '业务相关': [['去', '业务']],\n",
       " '业务': [['吃东西'], ['打水仗'], ['捉水母']],\n",
       " '结尾': [['吗？']]}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_grammar(Partick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'海绵宝宝': [['海绵宝宝', '派大星', '蟹老板']],\n",
       " '自己': [['我'], ['本宝宝'], ['派大星我们']],\n",
       " '寻找': [['看看'], ['玩玩'], ['去捉']],\n",
       " '活动': [['捉水母'], ['蟹黄包']]}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_grammar(SpongeBob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'海绵宝宝,你好吗你想去捉水母吗？'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(gram=create_grammar(Partick,split='='),target='Partick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = random.choice\n",
    "def generate(gram, target):\n",
    "    if target not in gram: return target # means target is a terminal expression\n",
    "    expaned = [generate(gram, t) for t in choice(gram[target])]\n",
    "    return ''.join([e if e != '/n' else '\\n' for e in expaned if e != 'null'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好你想去打水仗吗？\n",
      "你好你无聊吗想去打水仗吗？\n",
      "你好吗你无聊吗想去打水仗吗？\n",
      "你好你想去吃东西吗？\n",
      "蟹老板,你好吗你无聊吗想去打水仗吗？\n",
      "你好你想去打水仗吗？\n",
      "蟹老板,你好吗你无聊吗想去吃东西吗？\n",
      "你好你无聊吗想去捉水母吗？\n",
      "蟹老板,你好你想去捉水母吗？\n",
      "你好吗你无聊吗想去吃东西吗？\n",
      "你好你想去捉水母吗？\n",
      "你好吗你无聊吗想去吃东西吗？\n",
      "海绵宝宝,你好吗你无聊吗想去打水仗吗？\n",
      "你好你无聊吗想去吃东西吗？\n",
      "你好你无聊吗想去打水仗吗？\n",
      "海绵宝宝,你好你无聊吗想去吃东西吗？\n",
      "你好你想去吃东西吗？\n",
      "你好吗你想去捉水母吗？\n",
      "海绵宝宝,你好吗你想去吃东西吗？\n",
      "海绵宝宝,你好你无聊吗想去捉水母吗？\n"
     ]
    }
   ],
   "source": [
    "for i in range (20):\n",
    "    print (generate(gram=create_grammar(Partick,split='='),target='Partick'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'movie_comments.csv.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (0,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "content = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京意淫到了脑残的地步，看了恶心想吐</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>中二得很</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                        link name  \\\n",
       "0  1  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "1  2  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "2  3  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "3  4  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "4  5  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "\n",
       "                                             comment star  \n",
       "0                                 吴京意淫到了脑残的地步，看了恶心想吐    1  \n",
       "1  首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...    2  \n",
       "2  吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...    2  \n",
       "3                      凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。    4  \n",
       "4                                               中二得很    1  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = content['comment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261497"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'生活总有这样那样说得出说不出的苦，也许比想象中还要糟一点，但只有咬牙坚持下去，每天给自己一个微笑然后继续努力，总有一天幸福会不期而遇'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment[151]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\heipi\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.527 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "with_jieba_cut =Counter(jieba.cut(articles[11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(string):\n",
    "    return re.findall('\\w+', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_clean = [''.join(token(str(a))) for a in comment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('movie_commentscl.csv.txt','w',encoding='utf-8') as f:\n",
    "    for a in comment_clean:\n",
    "        f.write(a + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261497"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comment_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(string): return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n"
     ]
    }
   ],
   "source": [
    "for i,line in enumerate ((open ('movie_commentscl.csv.txt','rb'))):\n",
    "    if i%10000==0:\n",
    "        print (i)\n",
    "    if i >270000:break\n",
    "    TOKEN+=cut(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9503620"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 656524),\n",
       " ('\\r\\n', 522994),\n",
       " ('了', 204840),\n",
       " ('是', 146212),\n",
       " ('我', 100676),\n",
       " ('都', 72510),\n",
       " ('很', 69424),\n",
       " ('看', 68044),\n",
       " ('电影', 67350),\n",
       " ('也', 64130),\n",
       " ('和', 62580),\n",
       " ('在', 62490),\n",
       " ('不', 56870),\n",
       " ('有', 55878),\n",
       " ('就', 51370),\n",
       " ('人', 47818),\n",
       " ('好', 45716),\n",
       " ('啊', 41606),\n",
       " ('这', 34968),\n",
       " ('还', 34898),\n",
       " ('一个', 34686),\n",
       " ('你', 34564),\n",
       " ('还是', 32850),\n",
       " ('但', 31156),\n",
       " ('故事', 30020),\n",
       " ('没有', 28686),\n",
       " ('就是', 28014),\n",
       " ('喜欢', 27132),\n",
       " ('让', 26608),\n",
       " ('太', 25352),\n",
       " ('又', 23132),\n",
       " ('剧情', 22718),\n",
       " ('没', 21716),\n",
       " ('说', 21528),\n",
       " ('吧', 21494),\n",
       " ('他', 21350),\n",
       " ('不错', 20832),\n",
       " ('得', 20698),\n",
       " ('到', 20682),\n",
       " ('给', 20600),\n",
       " ('这个', 20116),\n",
       " ('上', 20108),\n",
       " ('被', 19878),\n",
       " ('对', 19648),\n",
       " ('最后', 19388),\n",
       " ('一部', 19386),\n",
       " ('片子', 19180),\n",
       " ('什么', 19142),\n",
       " ('能', 19064),\n",
       " ('与', 18336),\n",
       " ('多', 17954),\n",
       " ('可以', 17944),\n",
       " ('不是', 17622),\n",
       " ('最', 17338),\n",
       " ('觉得', 17252),\n",
       " ('中', 16892),\n",
       " ('导演', 16780),\n",
       " ('自己', 16708),\n",
       " ('拍', 16344),\n",
       " ('好看', 16170),\n",
       " ('要', 16162),\n",
       " ('真的', 15816),\n",
       " ('感觉', 15656),\n",
       " ('但是', 15446),\n",
       " ('里', 15310),\n",
       " ('那', 15006),\n",
       " ('有点', 14958),\n",
       " ('想', 14884),\n",
       " ('这部', 14866),\n",
       " ('会', 14858),\n",
       " ('去', 14590),\n",
       " ('把', 14302),\n",
       " ('着', 14116),\n",
       " ('这么', 13568),\n",
       " ('小', 13252),\n",
       " ('个', 13092),\n",
       " ('而', 13014),\n",
       " ('这样', 12942),\n",
       " ('真是', 12898),\n",
       " ('那么', 12862),\n",
       " ('这种', 12754),\n",
       " ('片', 12666),\n",
       " ('不过', 12584),\n",
       " ('挺', 12488),\n",
       " ('时候', 12432),\n",
       " ('更', 12286),\n",
       " ('比', 12188),\n",
       " ('却', 11980),\n",
       " ('爱', 11818),\n",
       " ('我们', 11750),\n",
       " ('大', 11546),\n",
       " ('像', 11408),\n",
       " ('虽然', 11266),\n",
       " ('演技', 11262),\n",
       " ('其实', 11146),\n",
       " ('看到', 10900),\n",
       " ('知道', 10768),\n",
       " ('再', 10704),\n",
       " ('演员', 10656),\n",
       " ('那个', 10246)]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count = Counter(TOKEN)\n",
    "words_count.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_1(word):\n",
    "    return words_count[word]/len(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010593437027153863"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_1('我')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['吴京', '意淫', '到', '了', '脑残', '的', '地步', '看', '了', '恶心']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN =[str(t) for t in TOKEN]\n",
    "TOKEN_2_GRAM = [''.join(TOKEN[i:i+2]) for i in range (len(TOKEN))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count_2=Counter(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_2(word1, word2):\n",
    "    if word1+word2 in words_count_2:\n",
    "        return words_count_2[word1+word2]/len(TOKEN_2_GRAM)\n",
    "    else:\n",
    "        return 1/len(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0202827975024253e-05"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2('我们', '在')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probablity (sentence):\n",
    "    words = cut(sentence)\n",
    "    sentence_pro = 1\n",
    "    for i, word in enumerate (words[:-1]):\n",
    "        next_ = words [i+1]\n",
    "        probablity = prob_2(word, next_)\n",
    "        sentence_pro*=probablity\n",
    "    return sentence_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0522306236991799e-07"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_probablity('战狼真难看')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.313383742195079e-07"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_probablity('海绵宝宝')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 获得最优质的的语言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    " setence=[]\n",
    "for sen in [generate(gram=create_grammar(Partick,split='='), target='Partick') for i in range(20)]:\n",
    "    setence.append((sen,get_probablity(sen)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('你好你想去捉水母吗？', 8.686862790619655e-43),\n",
       " ('你好吗你想去吃东西吗？', 1.790091784935586e-44),\n",
       " ('你好你无聊吗想去打水仗吗？', 8.309620956511742e-51),\n",
       " ('你好你无聊吗想去打水仗吗？', 8.309620956511742e-51),\n",
       " ('你好你无聊吗想去吃东西吗？', 1.4269616631375372e-53),\n",
       " ('你好吗你无聊吗想去打水仗吗？', 8.393892136103162e-56),\n",
       " ('海绵宝宝,你好你想去打水仗吗？', 7.213501054463657e-57),\n",
       " ('你好吗你无聊吗想去吃东西吗？', 1.4414330503661087e-58),\n",
       " ('海绵宝宝,你好吗你想去打水仗吗？', 7.286656045049265e-62),\n",
       " ('蟹老板,你好吗你想去打水仗吗？', 1.2144426741748774e-62),\n",
       " ('蟹老板,你好吗你想去打水仗吗？', 1.2144426741748774e-62),\n",
       " ('蟹老板,你好吗你想去打水仗吗？', 1.2144426741748774e-62),\n",
       " ('海绵宝宝,你好吗你想去吃东西吗？', 1.2512939980260575e-64),\n",
       " ('海绵宝宝,你好你无聊吗想去打水仗吗？', 5.808517147699688e-71),\n",
       " ('海绵宝宝,你好你无聊吗想去吃东西吗？', 9.974620181621203e-74),\n",
       " ('海绵宝宝,你好吗你无聊吗想去打水仗吗？', 5.867423636247765e-76),\n",
       " ('海绵宝宝,你好吗你无聊吗想去捉水母吗？', 4.939106265821037e-82),\n",
       " ('海绵宝宝,你好吗你无聊吗想去捉水母吗？', 4.939106265821037e-82),\n",
       " ('蟹老板,你好吗你无聊吗想去捉水母吗？', 8.231843776368395e-83),\n",
       " ('蟹老板,你好吗你无聊吗想去捉水母吗？', 8.231843776368395e-83)]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted (setence,key=lambda x:x[1],reverse=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A\n",
    "\n",
    "\n",
    "0. Can you come up out 3 sceneraies which use AI methods?  \n",
    " Siri,  Autopilot,  Smart home\n",
    " \n",
    " \n",
    "1. How do we use Github; Why do we use Jupyter and Pycharm;  \n",
    "See paper and code on Github. Put assignment on Github.  Jupyter is a clear and useful tool to demonstrate the code. Pycharm could be the most powerful tool for python program.\n",
    "2.What's the Probability Model?\n",
    "The Probability Model is a mathematical model used to describe the relationship between different random variables. Usually, the probability relationship between one or more random variables is deciphered.\n",
    "\n",
    "\n",
    "3. Can you came up with some sceneraies at which we could use Probability Model?  \n",
    "Predict the stock market,  gambling,  Intelligent Transportation System\n",
    "\n",
    "\n",
    "4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?  \n",
    "Because so many real world data is unstructured, so coding based on the pattern match could be very complicated .\n",
    "5.What's the Language Model;\n",
    "A statistical language model is a probability distribution over sequences of words. Given such a sequence, say of length m, it assigns a probability to the whole sequence.\n",
    "\n",
    "\n",
    "6. Can you came up with some sceneraies at which we could use Language Model?  \n",
    "Recognize Speech, translate, Generate speech\n",
    "\n",
    "\n",
    "7. What's the 1-gram language model  \n",
    "The model the assigns the probabilities of a word.\n",
    "\n",
    "\n",
    "8. What's the disadvantages and advantages of 1-gram language model;  \n",
    "1-gram model just contain one word. But the real word sentence contain so many words, that means the probabilities of one world do not the follow the rules of a sentence. So 1-gram model can not get good result on sentence. \n",
    "\n",
    "9. What't the 2-gram models;\n",
    "The model that assigns these probabilities to sentences or sequence of words is N-Gram. An N-gram is a sequence of N words: a 2-gram is a two-word sequence of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
